{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Транскрибация в облаках при поддержке панд"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как часто нам приходится выступать с докладом, презентацией, проводить обучение, быть спикером на конференции? Если деятельность напрямую не связана с человеческим общением, навык грамотно доносить свою точку зрения теряется естественным образом. Друзья и близкие зачастую воспринимают нас “как есть”, исключая обратную связь для сохранения отношений. Несмотря на лояльность друзей и коллег, практика публичных выступлений важна и необходима для поддержания способности передавать свои мысли и чувства.\n",
    "\n",
    "Данная статья поможет разобраться с нашими вербальными привычками и подсветит зоны роста. К её созданию меня подтолкнул спикер одного из youtube каналов it-направленности. Его речь, наполненная идиомами и вводными словами, мешала восприятию основного полезного контента. Впоследствии родилась идея перевести аудиозаписи роликов в текст и выяснить, какие выражения чаще других перегружают речь. Первой задачей стала транскрибация целевой аудиодорожки, второй – анализ текста, третьей - выводы и работа над ошибками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Транскрибация**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск качественного инструмента для анализа аудио свелся к выбору между облачными сервисами, решения доступные 'for free' в открытых репозиториях не соответствовали моим ожиданиям по качеству результата. Адекватное решение, способное обрабатывать длинные записи, нашлось только у тындекса. После нетривиальных настроек облака стал доступен API асинхронного распознавания. Настройки сервиса описаны здесь: cloud.yandex.ru/docs/speechkit/. \n",
    "Для теста была записана аудиодорожка с моими впечатлениями за текущий год. Далее в коде используется именно она."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка mp3-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключаемся к cloud.yandex.ru , проходим все стартовые настройки сервера и рабочего пространства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заливаем аудиозапись в выделенное хранилище облака, назначаем права на чтение сервису Speech_Kit, копируем ссылку на файл, вставляем её в POST-запрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры запроса\n",
    "key = 'ваш API - key yc’\n",
    "\n",
    "# путь к файлу в бакете YC\n",
    "filelink = 'https://storage.yandexcloud.net/bucket0011/test_audio.mp3' \n",
    "   \n",
    "body ={\n",
    "    \"config\": {\n",
    "        \"specification\": {\n",
    "            \"languageCode\": \"ru-RU\"\n",
    "            , \"audioEncoding\": \"MP3\"\n",
    "        }\n",
    "    },\n",
    "    \"audio\": {\n",
    "        \"uri\": filelink\n",
    "    }\n",
    "}\n",
    "\n",
    "header = {'Authorization': 'Api-Key {}'.format(key)}\n",
    "POST = \"https://transcribe.api.cloud.yandex.net/speech/stt/v2/longRunningRecognize\"\n",
    "\n",
    "# структура POST - запроса согласно инструкции API\n",
    "req = requests.post(POST, headers=header, json=body)\n",
    "\n",
    "#Получаем ответ от сервера, из которого забирам ID задачи на обработку аудиозаписи.\n",
    "data = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = data['id']  \n",
    "print(id_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запрашиваем на сервере статус операции раз в 10 секунд и ожидаем окончания процесса распознавания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    # проверяем распознано ли аудио\n",
    "    GET = \"https://operation.api.cloud.yandex.net/operations/{id}\"\n",
    "    req = requests.get(GET.format(id=id_), headers=header)\n",
    "    req = req.json()\n",
    "    # если распознано — выходим из цикла\n",
    "    if req['done']: break\n",
    "    # если нет — выводим сообщение\n",
    "    print(\"файл в обработке\")\n",
    "    # ждём 10 секунд\n",
    "    time.sleep(10)\n",
    "\n",
    "#создаем временные хранилища\n",
    "all_sentenses = []\n",
    "sentenses_dic = {}\n",
    "all_text =''\n",
    "for id,chunk in enumerate(req['response']['chunks']):\n",
    "#     if id%2==1:  #актуально только для двухканального аудио\n",
    "\n",
    "    chnk = chunk['alternatives'][0]['text'].lower()\n",
    "    all_text = all_text+chnk+' '\n",
    "        \n",
    "print(\"Часть распознанного текста: \",all_text[:55])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переводим весь текст в нижний регистр, чистим от знаков пунктуации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = all_text.lower()\n",
    "all_text = all_text.replace('.','').replace(',','').replace(' - ','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ текста**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем уникальные идиомы из двух слов, не подпадающие под стандартные речевые обороты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_pairs_dic(data):\n",
    "   \n",
    "    dic_words_order1 = {}\n",
    "    counter=0\n",
    "    for num, word in enumerate(data.split()):\n",
    "\n",
    "        dic_words_order1[num] = word\n",
    "\n",
    "    all_p =[]\n",
    "    all_p2 =[]\n",
    "    pair=[]\n",
    "    pair2=[]\n",
    "    p=''\n",
    "    p2=''\n",
    "    cnt2=0\n",
    "    for word in dic_words_order1.items():\n",
    "        pair.append(word[1])\n",
    "\n",
    "    #     сочетания двух слов\n",
    "        pair2.append(word[1])\n",
    "        if int(word[0])%2==0:        \n",
    "            try:\n",
    "                p = pair[0]+' '+pair[1]\n",
    "            except:\n",
    "                pass\n",
    "            all_p.append(p)\n",
    "            pair=[]\n",
    "\n",
    "    #     сочетания двух слов со смещением на 1 слово\n",
    "        if int(word[0])%2==1:\n",
    "\n",
    "            try:\n",
    "                p2 = pair2[0]+' '+pair2[1]\n",
    "            except:\n",
    "                pass\n",
    "            all_p2.append(p2)\n",
    "            pair2=[]\n",
    "\n",
    "    #  ------------ чистим списки от пробелов -----------------\n",
    "    try:\n",
    "        all_p.pop(all_p.index(''))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        all_p2.pop(all_p2.index(''))\n",
    "    except:\n",
    "        pass\n",
    "    # -------------- удаляем дубликаты ------------------\n",
    "    all_p = list(set(all_p))\n",
    "    all_p2 = list(set(all_p2))\n",
    "\n",
    "    return all_p ,all_p2\n",
    "all_pairs1 ,all_pairs2 = get_word_pairs_dic(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем количество повторений пар из 2 слов в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_counter(pair_list,text):\n",
    "    phrase_dic = dict(zip(pair_list,[text.count(k) for k in pair_list ]))\n",
    "    df_phrase = pd.DataFrame.from_dict(phrase_dic,  orient='index')\n",
    "    df_phrase = df_phrase.reset_index().rename(columns={'index': 'word_pair', 0: 'count'})\n",
    "    df_phrase.where(df_phrase['word_pair'].str.len()>5).sort_values(by='count', ascending = False)\n",
    "    \n",
    "    return df_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pairs_count_results(pair_list, pair_list2, text):\n",
    "    df_pairs = pair_counter(pair_list, text)\n",
    "    df_pairs2 = pair_counter(pair_list2, text)\n",
    "    combine_df = pd.concat([df_pairs,df_pairs2])\n",
    "    combine_df = combine_df.where(combine_df['word_pair'].str.len()>5).drop_duplicates()\n",
    "    .sort_values(by='count', ascending = False)\n",
    "    \n",
    "    return combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем результаты и оставляем уникальные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_pair</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>это был</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>в общем</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>и потом</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>22 год</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>был еще</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_pair  count\n",
       "105   это был    6.0\n",
       "28    в общем    4.0\n",
       "55    и потом    3.0\n",
       "81     22 год    3.0\n",
       "71    был еще    3.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = combine_pairs_count_results(all_pairs1, all_pairs2,all_text)\n",
    "combine_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Промежуточные выводы: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В тексте часто повторяется фраза \"это был\"\n"
     ]
    }
   ],
   "source": [
    "most_popular_phrase = combine_df.iloc[0]['word_pair']\n",
    "print(f'В тексте часто повторяется фраза \"{most_popular_phrase}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы ищем конкретные речевые обороты, можно упростить процесс перебора, задав их в явном виде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_word_dic = {}\n",
    "bad_words = ['то есть','по моему','по-моему','честно говоря','как бы','так сказать','по сути','собственно говоря','как бы'\n",
    "             ,'таким образом','как говорится','так далее','как его','так вот','как сказать','на самом деле','в общем-то'\n",
    "             ,'в общем','в некотором роде','в принципе','типа того','в самом деле','всё такое','в целом','то есть'\n",
    "             ,'это самое','ну вот','ну это','так сказать','да ладно', 'можно сказать', 'как-то','не вопрос','без проблем'\n",
    "             ,'как-то так','ничего себе','соответственно']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь повторений выбранных фраз в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_phrase_counter(text):\n",
    "    dic = dict(zip(bad_words,[text.count(k) for k in bad_words ]))\n",
    "    df = pd.DataFrame.from_dict(dic,  orient='index')\n",
    "    df = df.reset_index().rename(columns={'index': 'word', 0: 'count'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем повторения слов-паразитов в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>в общем</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>по моему</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>в принципе</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>типа того</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>в самом деле</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count\n",
       "16       в общем      4\n",
       "1       по моему      1\n",
       "18    в принципе      0\n",
       "19     типа того      0\n",
       "20  в самом деле      0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = bad_phrase_counter(all_text)\n",
    "df.sort_values(by='count', ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем количество повторений отдельных слов в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(all_sentenses):\n",
    "    all_words = []\n",
    "    for sentance in all_sentenses:\n",
    "        for word in sentance.split(sep=' '):\n",
    "            word = word.lower()\n",
    "            if len(word)>=2:\n",
    "                all_words.append(word)\n",
    "    unique = dict(zip(all_words,[all_words.count(i) for i in all_words]))\n",
    "    df = pd.DataFrame.from_dict(unique,  orient='index')\n",
    "    df2 =df.reset_index().rename(columns={'index': 'word', 0: 'count'})\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>это</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>на</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>что</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>не</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>так</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "71  это     14\n",
       "12   на     10\n",
       "33  что     10\n",
       "56   не     10\n",
       "22  так     10"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentenses = all_text.split()\n",
    "df_words = word_counter(all_sentenses)\n",
    "df_words.sort_values(by='count', ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим самую \"вредную\" фразу из всего текста, даем рекомендации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые популярные выражения в вашей речи - \"это был\" и \"в общем\".\n",
      "Ознакомьтесь, пожалуйста, с их синонимами: \n",
      "https://sinonim.org/s/это%20был \n",
      "https://sinonim.org/s/в%20общем\n"
     ]
    }
   ],
   "source": [
    "bad_word = str(combine_df.iloc[0]['word_pair'])\n",
    "bad_word2 = str(combine_df.iloc[1]['word_pair'])\n",
    "print(f'Самые популярные выражения в вашей речи - \"{bad_word}\" и \"{bad_word2}\".')\n",
    "word_to_post = bad_word.replace(' ','%20')\n",
    "word_to_post2 = bad_word2.replace(' ','%20')\n",
    "print(f'Ознакомьтесь, пожалуйста, с их синонимами: \\nhttps://sinonim.org/s/\n",
    "      {word_to_post} \\nhttps://sinonim.org/s/{word_to_post2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Историческое отступление."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стив Джобс**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте немного отвлечемся и для проверки работы скрипта возьмем текст презентации компании Apple 2007 года, где исполнительный директор анонсировал первый мобильный телефон компании с сенсорным дисплеем и функцией геолокации. Анализ текста позволит нам понять какие фразы Стив Джобс использовал для представления своего нового творения общественности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для упрощения процесса загружаем речь спискеров с сайта https://singjupost.com/ по ссылке:\n",
    "https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставляем только речь Стива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('apple2007_.txt','r') as file:\n",
    "    presentation_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the day i’ve been looking forward to for two and a half years\n",
      "every once in a while a revolutionary product comes along that changes everything and\n",
      "apple has been – well first of all one’s very fortunate\n"
     ]
    }
   ],
   "source": [
    "presentation_text = presentation_text.replace('.','').replace(',','').replace(' - ','')\n",
    "presentation_text = presentation_text.lower()\n",
    "print(presentation_text[:211])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем текст на пары рядом стоящих слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['completely automatically',\n",
       " 'hold on',\n",
       " 'wide screen',\n",
       " 'mail this',\n",
       " 'are calling']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_p ,all_p2 = get_word_pairs_dic(presentation_text)\n",
    "all_p[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем количество повторений пар слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_pair</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>going to</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>want to</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>i want</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>this i</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>here a</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>this is</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>here and</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>in the</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>here i</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>you can</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_pair  count\n",
       "1456  going to   68.0\n",
       "1375   want to   57.0\n",
       "2436    i want   47.0\n",
       "2139    this i   44.0\n",
       "2444    here a   42.0\n",
       "2942   this is   40.0\n",
       "3069  here and   39.0\n",
       "930     in the   38.0\n",
       "2777    here i   35.0\n",
       "2473   you can   33.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df2 = combine_pairs_count_results(all_p, all_p2,presentation_text)\n",
    "combine_df2[:10].sort_values(by='count', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из приведенного результата видно, что речь Cтива наполнена фразами про намерение, желание и простоту. Этот посыл передается аудитории и то, как он вдохновленно рассказывает о новом устройстве и то, как умело использует его в своих руках. Любой человек подсознательно проникнется такой подачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подводя итог, мы выяснили, что речь - сильный инструмент, способный убеждать, если вы используете верные слова и честны с аудиторией. \n",
    "\n",
    "Данное исследование позволяет легко проанализировать аудиозапись или готовый текст. Получив самые популярные фразы в речи, мы cможем понять на сколько они ценны и наоборот бесполезны. Проанализировав результаты мы сможем улучшить качество высказываний для нашего слушателя, а значит станем приятным собеседником или успешным спикером."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
